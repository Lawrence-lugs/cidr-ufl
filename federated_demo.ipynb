{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the CIDR DL Framework!\n",
    "\n",
    "This framework contains sample implementations of FL using *Flower* and *Pytorch* \n",
    "\n",
    "To get started with the demo for Federated Learning under the framework, let's start with a demonstration of CIFAR10. Let's get all the dependencies with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray after 1.11.1 has a memory leak when used with flower\n",
    "!pip install ray=1.11.1\n",
    "!pip install flwr[\"simulation\"]\n",
    "git clone https://github.com/Lawrence-lugs/cidr-ufl\n",
    "\n",
    "\n",
    "!./get_dataset.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with the framework, we first import the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dl_framework\n",
    "\n",
    "my_config = dl_framework.fw_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fist, we set the locations for the simulation's output data (we'll view this later with tensorboard)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config.tensorboard_runs_dir = 'tb_data/sample'\n",
    "my_config.run_name = 'demo'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set the general settings for the distributed learning simulation. Note that all of these have default values so you can actually skip everything. Look into `dl_framework/__init__.py` to see the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config.num_nodes = 2\n",
    "my_config.clients_per_gpu = 1 # careful when setting this to more than 1, you'll probably need more than a GTX 1080T\n",
    "my_config.num_rounds = 10\n",
    "my_config.local_epochs = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, we define the node class that the framework will use. In the framework, we define & use `dl_framework.dp_node` and `dl_framework.dl_model` objects to specify the behavior of the node, including the training algorithm and the model.\n",
    "\n",
    "This is compatible with any AI framework, so long as you can inherit and define the necessary classes.\n",
    "\n",
    "For now, let's settle with using a premade node & model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dl_framework.node\n",
    "my_config.node_class = dl_framework.node.dl_node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to configure, which is not optional (there are no default values for this one) is the testset and the trainset(s).\n",
    "\n",
    "We'll need to define the trainset as a list of two trainsets, since we have two nodes.\n",
    "\n",
    "Below is code that can create any number of IID subsets of the toycar dataset (this framework should be able to handle non-IID subsets, as it is based on **Flower** and **FedAvg** - experiments with such are still to follow but are easy to implement in the framework by editing the code below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "def split_dataset(trainset: torch.utils.data.dataset.Dataset,num_nodes: int):\n",
    "\n",
    "    torchseed = torch.Generator().manual_seed(42)\n",
    "    dataset_shares = [1 / num_nodes] * num_nodes\n",
    "\n",
    "    import numpy as np\n",
    "    print(np.sum(dataset_shares))\n",
    "\n",
    "    local_trainsets = torch.utils.data.random_split(trainset, dataset_shares, torchseed)\n",
    "\n",
    "    return local_trainsets \n",
    "\n",
    "import torchvision\n",
    "import image_classification.utils\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=True,\n",
    "        download=False,\n",
    "        transform=image_classification.utils.t_cropflip_augment\n",
    "    )\n",
    "trainsets = split_dataset(trainset,my_config.num_nodes)\n",
    "trainset = None\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=False,\n",
    "        download=False,\n",
    "        transform=image_classification.utils.t_normalize\n",
    "    )\n",
    "\n",
    "my_config.testset = testset\n",
    "my_config.trainsets = trainsets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to view the outputs, we need to open the tensorboard server. Personally, I would open a browser to look at `localhost:6006` instead of viewing it here for a better experience.\n",
    "\n",
    "When using the framework without this notebook, you'll have to open tensorboard using the same command as below, but in a terminal. `tensorboard --logdir tb_data/sample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-36f8d1a0059db306\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-36f8d1a0059db306\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir tb_data/sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's start the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dl_framework.framework as framework\n",
    "framework.run(my_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
